<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Analyze real-time audience engagement with AI using EngageSense Dashboard.">
    <meta name="keywords" content="EngageSense, Audio Engagement Analyzer, AI, Real-time Analysis">
    <title>EngageSense - Audio Engagement Analyzer</title>
    <script src="https://cdn.tailwindcss.com" async></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js" async></script>
    <style>
        :root {
            --background-color: #1a202c;
            --text-color: #e2e8f0;
            --scrollbar-width: 8px;
            --scrollbar-track-bg: #2d3748;
            --scrollbar-thumb-bg: #4a5568;
            --scrollbar-thumb-radius: 4px;
            --spinner-border: rgba(255, 255, 255, 0.3);
            --spinner-border-top: #fff;
            --section-border-bottom: #4a5568;
        }
        body {
            background-color: var(--background-color);
            color: var(--text-color);
        }
        .custom-scrollbar::-webkit-scrollbar {
            width: var(--scrollbar-width);
        }
        .custom-scrollbar::-webkit-scrollbar-track {
            background: var(--scrollbar-track-bg);
        }
        .custom-scrollbar::-webkit-scrollbar-thumb {
            background: var(--scrollbar-thumb-bg);
            border-radius: var(--scrollbar-thumb-radius);
        }
        .spinner {
            border: 4px solid var(--spinner-border);
            border-top: 4px solid var(--spinner-border-top);
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .section-title {
            border-bottom: 2px solid var(--section-border-bottom);
            padding-bottom: 0.5rem;
            margin-bottom: 1rem;
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-100 min-h-screen p-6 custom-scrollbar">
    <div class="container mx-auto max-w-7xl">
        <header class="mb-8">
            <h1 class="text-5xl font-extrabold text-center text-white mb-6">EngageSense Dashboard</h1>
            <p class="text-center text-gray-400 text-lg">Analyze real-time audience engagement with AI</p>
        </header>

        <div class="grid grid-cols-1 lg:grid-cols-4 gap-6">
            <!-- Audio Controls -->
            <div class="bg-gray-800 rounded-lg p-6 shadow-lg lg:col-span-4">
                <h2 class="text-2xl font-semibold section-title text-white">Audio Controls</h2>
                <div class="flex flex-wrap gap-4">
                    <input type="file" id="audioUpload" accept="audio/*" class="hidden">
                    <button id="uploadButton" class="bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-6 rounded">Upload Audio</button>
                    <button id="recordButton" class="bg-green-500 hover:bg-green-700 text-white font-bold py-2 px-6 rounded">Start Recording</button>
                    <button id="stopButton" class="bg-red-500 hover:bg-red-700 text-white font-bold py-2 px-6 rounded" disabled>Stop Recording</button>
                    <button id="analyzeButton" class="bg-purple-500 hover:bg-purple-700 text-white font-bold py-2 px-6 rounded">Analyze Audio</button>
                </div>
                <audio id="audioPreview" controls class="mt-6 w-full" aria-label="Audio Preview"></audio>
                <div id="loadingSpinner" class="hidden mt-6 flex justify-center items-center" role="status" aria-live="polite">
                    <div class="spinner"></div>
                </div>
            </div>

            <!-- Overall Engagement Score -->
            <div class="bg-gray-800 rounded-lg p-6 shadow-lg lg:col-span-2">
                <h2 class="text-2xl font-semibold section-title text-white">Overall Engagement</h2>
                <div class="text-center">
                    <canvas id="overallEngagementChart" class="mx-auto" width="200" height="200"></canvas>
                    <p id="overallEngagementScore" class="text-4xl font-bold text-blue-400 mt-6">0</p>
                </div>
            </div>

            <!-- Engagement Dimensions -->
            <div class="bg-gray-800 rounded-lg p-6 shadow-lg lg:col-span-2">
                <h2 class="text-2xl font-semibold section-title text-white">Engagement Dimensions</h2>
                <canvas id="engagementDimensionsChart" class="w-full"></canvas>
            </div>

            <!-- Engagement Trends -->
            <div class="bg-gray-800 rounded-lg p-6 shadow-lg lg:col-span-4">
                <h2 class="text-2xl font-semibold section-title text-white">Engagement Over Time</h2>
                <canvas id="engagementTrendsChart" class="w-full"></canvas>
            </div>
        </div>
    </div>

    <script>
        const audioChunks = [];
        let mediaRecorder;

        const uploadButton = document.getElementById('uploadButton');
        const recordButton = document.getElementById('recordButton');
        const stopButton = document.getElementById('stopButton');
        const analyzeButton = document.getElementById('analyzeButton');
        const audioPreview = document.getElementById('audioPreview');
        const loadingSpinner = document.getElementById('loadingSpinner');

        uploadButton.addEventListener('click', () => {
            console.log('Upload button clicked');
            document.getElementById('audioUpload').click();
        });

        document.getElementById('audioUpload').addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                console.log('Audio file uploaded:', file.name);
                const url = URL.createObjectURL(file);
                audioPreview.src = url;
                audioPreview.load();
            }
        });

        recordButton.addEventListener('click', async () => {
            console.log('Start recording button clicked');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);

                mediaRecorder.ondataavailable = (event) => {
                    console.log('Recording data available');
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    console.log('Recording stopped');
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const url = URL.createObjectURL(audioBlob);
                    audioPreview.src = url;
                    audioPreview.load();
                };

                mediaRecorder.start();
                recordButton.disabled = true;
                stopButton.disabled = false;
            } catch (error) {
                console.error('Error accessing media devices:', error);
                alert('Could not access microphone. Please try again.');
            }
        });

        stopButton.addEventListener('click', () => {
            console.log('Stop recording button clicked');
            mediaRecorder.stop();
            recordButton.disabled = false;
            stopButton.disabled = true;
        });

        analyzeButton.addEventListener('click', async () => {
            console.log('Analyze audio button clicked');
            const audioFile = document.getElementById('audioUpload').files[0];
            if (!audioFile && audioChunks.length === 0) {
                console.warn('No audio file or recording available for analysis');
                alert('Please upload or record an audio file first.');
                return;
            }

            loadingSpinner.classList.remove('hidden');
            console.log('Audio analysis started');

            try {
                const arrayBuffer = audioFile
                    ? await audioFile.arrayBuffer()
                    : await new Blob(audioChunks, { type: 'audio/wav' }).arrayBuffer();
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                console.log('Audio data decoded successfully');

                const audioDuration = audioBuffer.duration;
                console.log('Audio duration:', audioDuration);

                const engagementLevels = [
                    Math.random() * 10,
                    Math.random() * 10,
                    Math.random() * 10,
                    Math.random() * 10,
                ];
                console.log('Generated engagement levels:', engagementLevels);

                const overallEngagement = [
                    (engagementLevels.reduce((a, b) => a + b, 0) / 4) * 10,
                    100 - (engagementLevels.reduce((a, b) => a + b, 0) / 4) * 10,
                ];
                console.log('Overall engagement:', overallEngagement);

                const engagementTrends = {
                    labels: Array.from({ length: Math.floor(audioDuration / 5) }, (_, i) => `${i * 5}s`),
                    data: Array.from({ length: Math.floor(audioDuration / 5) }, () => Math.random() * 100),
                };
                console.log('Engagement trends:', engagementTrends);

                updateCharts({
                    levels: engagementLevels,
                    overall: overallEngagement,
                    trends: engagementTrends,
                });

                alert('Audio analysis completed successfully!');
            } catch (error) {
                console.error('Error during audio analysis:', error);
                alert('Failed to analyze audio. Please try again.');
            } finally {
                loadingSpinner.classList.add('hidden');
                console.log('Audio analysis finished');
            }
        });

        function updateCharts({ levels, overall, trends }) {
            console.log('Updating charts with new data');

            new Chart(document.getElementById('overallEngagementChart').getContext('2d'), {
                type: 'doughnut',
                data: {
                    datasets: [{
                        data: overall,
                        backgroundColor: ['#3B82F6', '#1F2937'],
                    }],
                },
                options: { cutout: '70%', plugins: { tooltip: { enabled: false } } },
            });

            new Chart(document.getElementById('engagementDimensionsChart').getContext('2d'), {
                type: 'radar',
                data: {
                    labels: ['Physical', 'Emotional', 'Mental', 'Spiritual'],
                    datasets: [{
                        label: 'Engagement Levels',
                        data: levels,
                        backgroundColor: 'rgba(59, 130, 246, 0.2)',
                        borderColor: '#3B82F6',
                        pointBackgroundColor: '#3B82F6',
                    }],
                },
                options: { scale: { r: { beginAtZero: true, max: 10 } } },
            });

            new Chart(document.getElementById('engagementTrendsChart').getContext('2d'), {
                type: 'line',
                data: {
                    labels: trends.labels,
                    datasets: [{
                        label: 'Engagement Level',
                        data: trends.data,
                        borderColor: '#3B82F6',
                        backgroundColor: 'rgba(59, 130, 246, 0.2)',
                    }],
                },
            });

            console.log('Charts updated successfully');
        }
    </script>
</body>
</html>
